{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe4a36eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import requests \n",
    "import shutil \n",
    "import time\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65e31781",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time \n",
    "import cv2\n",
    "import face_recognition\n",
    "import numpy as np\n",
    "from skimage import io\n",
    "from sklearn import svm\n",
    "from joblib import dump, load\n",
    "from PIL import Image, ImageDraw\n",
    "from sklearn.metrics import classification_report,accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71669ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "def append_row_to_csv(file_path, row):\n",
    "    with open(file_path, 'a', newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de510fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "path='E:/billboard/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b010a5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_records(ID,GENDER,AGE):\n",
    "    import datetime\n",
    "\n",
    "    # Get the current date and time\n",
    "    current_datetime = datetime.datetime.now()\n",
    "    current_date = datetime.date.today()\n",
    "\n",
    "    # Print current date\n",
    "    print(\"Current date is:\", current_date)\n",
    "    # Get the first day of the current month\n",
    "    first_day_of_month = datetime.datetime(current_datetime.year, current_datetime.month, 1)\n",
    "\n",
    "    # Calculate the number of weeks passed in the current month\n",
    "    weeks_passed_in_month = (current_datetime.day - 1) // 7 + 1\n",
    "\n",
    "    # Print the results\n",
    "    print(\"Current Day:\", current_datetime.strftime(\"%A\"))\n",
    "    print(\"Current Time:\", current_datetime.strftime(\"%H:%M:%S\"))\n",
    "    print(\"Week of the Month:\", weeks_passed_in_month)\n",
    "    day=str(current_datetime.strftime(\"%A\")).upper()\n",
    "    tym=int(current_datetime.strftime(\"%H\"))\n",
    "    \n",
    "    print(tym,type(tym))\n",
    "    tym1=''+str(tym)+\"-\"+str(tym+1)\n",
    "    print(ID,GENDER,AGE,current_date,tym1,day,'Week '+str(weeks_passed_in_month))\n",
    "    file_path = 'billboard_dataset.csv'\n",
    "    row_to_append = [ID,GENDER,AGE,current_date,tym1,day,'Week '+str(weeks_passed_in_month)]\n",
    "    append_row_to_csv(file_path, row_to_append)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bcd091ee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current date is: 2024-04-23\n",
      "Current Day: Tuesday\n",
      "Current Time: 17:13:28\n",
      "Week of the Month: 4\n",
      "17 <class 'int'>\n",
      "10 Male Adult 2024-04-23 17-18 TUESDAY Week 4\n"
     ]
    }
   ],
   "source": [
    "update_records(10,\"Male\",\"Adult\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "24bf89a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def face_recognition(input_image,count):\n",
    "    folders = []\n",
    "    import face_recognition\n",
    "    # r=root, d=directories, f = files\n",
    "    for r, d, f in os.walk(path+\"dataset\"):\n",
    "        for folder in d:\n",
    "            folders.append(folder)\n",
    "    print(folders)\n",
    "    known_face_encodings=[]\n",
    "    known_face_names=[]\n",
    "    for f in folders:\n",
    "        ifile=path+'Dataset/'+f+'/0.jpg'\n",
    "        print(ifile)\n",
    "        ru_image = face_recognition.load_image_file(ifile)\n",
    "        ru_face_encoding = face_recognition.face_encodings(ru_image)[0]\n",
    "        known_face_encodings.append(ru_face_encoding)\n",
    "        known_face_names.append(f)\n",
    "    print('done extraction')\n",
    "    clf = svm.SVC(gamma='scale')\n",
    "    clf.fit(known_face_encodings,known_face_names)\n",
    "    dump(clf,'SVM.Model')\n",
    "    print('done training')\n",
    "    try:\n",
    "        \n",
    "\n",
    "        unknown_image = face_recognition.load_image_file(input_image)\n",
    "        face_locations = face_recognition.face_locations(unknown_image)\n",
    "        face_encodings = face_recognition.face_encodings(unknown_image, face_locations)\n",
    "\n",
    "        pil_image = Image.fromarray(unknown_image)\n",
    "        draw = ImageDraw.Draw(pil_image)\n",
    "        for (top, right, bottom, left), face_encoding in zip(face_locations, face_encodings):\n",
    "            print('inside for')\n",
    "            matches = face_recognition.compare_faces(known_face_encodings, face_encoding)\n",
    "            name = \"Unknown Person\"\n",
    "\n",
    "            face_distances = face_recognition.face_distance(known_face_encodings, face_encoding)\n",
    "            best_match_index = np.argmin(face_distances)\n",
    "            if matches[best_match_index]:\n",
    "                name = known_face_names[best_match_index]\n",
    "            draw.rectangle(((left, top), (right, bottom)), outline=(0, 0, 255))\n",
    "            text_width, text_height = draw.textsize(name)\n",
    "            print(\"The Person is:\",name)\n",
    "        if name == \"Unknown Person\":\n",
    "            \n",
    "            un_image = cv2.imread(input_image)\n",
    "            cv2.imwrite(\"Unknown.jpg\",un_image)\n",
    "            #pil_image.save(\"Unknown.jpg\")\n",
    "            f=open(\"result.txt\",\"w\")\n",
    "            print((\"unknown\"),file = f)\n",
    "            f.close()\n",
    "\n",
    "            \n",
    "\n",
    "            folders = []\n",
    "\n",
    "            # r=root, d=directories, f = files\n",
    "            for r, d, f in os.walk(path+'Dataset'):\n",
    "                for folder in d:\n",
    "                    folders.append(folder)\n",
    "            print(folders)\n",
    "            os.mkdir(path+'Dataset/'+str(len(folders))) \n",
    "            cv2.imwrite(path+'Dataset/'+str(len(folders))+\"/0.jpg\",un_image)\n",
    "            known_face_encodings=[]\n",
    "            known_face_names=[]\n",
    "            for f in folders:\n",
    "                ifile=path+'Dataset/'+str(len(folders))+'/0.jpg'\n",
    "                print(ifile)\n",
    "                ru_image = face_recognition.load_image_file(ifile)\n",
    "                ru_face_encoding = face_recognition.face_encodings(ru_image)[0]\n",
    "                known_face_encodings.append(ru_face_encoding)\n",
    "                known_face_names.append(f)\n",
    "            clf = svm.SVC(gamma='scale')\n",
    "            print(len(known_face_encodings),len(known_face_names))\n",
    "            clf.fit(known_face_encodings,known_face_names)\n",
    "            dump(clf,'SVM.Model')\n",
    "            print('Retrained the model')\n",
    "        else:\n",
    "            f=open(\"result.txt\",\"w\")\n",
    "            str1=f'face_matched:{name}'\n",
    "            print(str1,file = f)\n",
    "            f.close()\n",
    "        uid=name\n",
    "        f=open('E:/billboard/output/'+str(count)+'_age.txt','r')\n",
    "        ag=f.read()\n",
    "        f.close()\n",
    "        f=open('E:/billboard/output/'+str(count)+'_gender.txt','r')\n",
    "        gen=f.read()\n",
    "        f.close()\n",
    "        update_records(uid,ag,gen)\n",
    "        draw.rectangle(((left, bottom - text_height - 10), (right, bottom)), fill=(0, 0, 255), outline=(0, 0, 255))\n",
    "        draw.text((left + 6, bottom - text_height - 5), name, fill=(255, 255, 255, 255))\n",
    "\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "82d63ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#face_recognition(path+'object_opencv/detected_faces/4.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b6d9892f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def highlightFace(net, frame, conf_threshold=0.7):\n",
    "    frameOpencvDnn=frame.copy()\n",
    "    frameHeight=frameOpencvDnn.shape[0]\n",
    "    frameWidth=frameOpencvDnn.shape[1]\n",
    "    blob=cv2.dnn.blobFromImage(frameOpencvDnn, 1.0, (300, 300), [104, 117, 123], True, False)\n",
    "\n",
    "    net.setInput(blob)\n",
    "    detections=net.forward()\n",
    "    faceBoxes=[]\n",
    "    for i in range(detections.shape[2]):\n",
    "        confidence=detections[0,0,i,2]\n",
    "        if confidence>conf_threshold:\n",
    "            x1=int(detections[0,0,i,3]*frameWidth)\n",
    "            y1=int(detections[0,0,i,4]*frameHeight)\n",
    "            x2=int(detections[0,0,i,5]*frameWidth)\n",
    "            y2=int(detections[0,0,i,6]*frameHeight)\n",
    "            faceBoxes.append([x1,y1,x2,y2])\n",
    "            cv2.rectangle(frameOpencvDnn, (x1,y1), (x2,y2), (0,255,0), int(round(frameHeight/150)), 8)\n",
    "    return frameOpencvDnn,faceBoxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2036af65",
   "metadata": {},
   "outputs": [],
   "source": [
    "faceProto=path+\"gender/opencv_face_detector.pbtxt\"\n",
    "faceModel=path+\"gender/opencv_face_detector_uint8.pb\"\n",
    "ageProto=path+\"gender/age_deploy.prototxt\"\n",
    "ageModel=path+\"gender/age_net.caffemodel\"\n",
    "genderProto=path+\"gender/gender_deploy.prototxt\"\n",
    "genderModel=path+\"gender/gender_net.caffemodel\"\n",
    "\n",
    "MODEL_MEAN_VALUES=(78.4263377603, 87.7689143744, 114.895847746)\n",
    "ageList=['(0-2)', '(4-6)', '(8-12)', '(15-20)', '(25-32)', '(38-43)', '(48-53)', '(60-100)']\n",
    "genderList=['Male','Female']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "81acb146",
   "metadata": {},
   "outputs": [],
   "source": [
    "faceNet=cv2.dnn.readNet(faceModel,faceProto)\n",
    "ageNet=cv2.dnn.readNet(ageModel,ageProto)\n",
    "genderNet=cv2.dnn.readNet(genderModel,genderProto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ee728278",
   "metadata": {},
   "outputs": [],
   "source": [
    "padding=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c12c4575",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = path+'final/detected_faces'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Load the pre-trained face detector\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "def detect_and_save_faces(frame, frame_count):\n",
    "    try:\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        faces = face_cascade.detectMultiScale(gray, scaleFactor=1.3, minNeighbors=5)\n",
    "        for i, (x, y, w, h) in enumerate(faces):\n",
    "            face = frame[y:y+h, x:x+w]\n",
    "            #face_file = os.path.join(output_dir, f'face_{frame_count}_{i}.jpg')\n",
    "            cv2.imwrite(output_dir+\"/\"+str(frame_count)+\".jpg\", face)\n",
    "            cv2.rectangle(frame, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "    except:\n",
    "        print('error in detect_and_save_faces')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "db076a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_output_layers(net):\n",
    "    \n",
    "    layer_names = net.getLayerNames()\n",
    "    try:\n",
    "        output_layers = [layer_names[i - 1] for i in net.getUnconnectedOutLayers()]\n",
    "    except:\n",
    "        output_layers = [layer_names[i[0] - 1] for i in net.getUnconnectedOutLayers()]\n",
    "\n",
    "    return output_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "640a65d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_prediction(i,img, class_id, confidence, x, y, x_plus_w, y_plus_h):\n",
    "    global path\n",
    "    print(y,y_plus_h,x, x_plus_w )\n",
    "    output_dir1 = path+'final/person/'\n",
    "    os.makedirs(output_dir1, exist_ok=True)\n",
    "    label = str(classes[class_id])\n",
    "\n",
    "    color = COLORS[class_id]\n",
    "\n",
    "    cv2.rectangle(img, (x,y), (x_plus_w,y_plus_h), color, 2)\n",
    "    crop_img = img[y:y_plus_h, x:x_plus_w]\n",
    "    cv2.imwrite(output_dir1+str(i)+'.jpg',crop_img)\n",
    "    \n",
    "    try:\n",
    "        resultImg,faceBoxes=highlightFace(faceNet,crop_img)\n",
    "        if not faceBoxes:\n",
    "            print(\"No face detected\")\n",
    "        else:\n",
    "            \n",
    "            for faceBox in faceBoxes:\n",
    "                face=crop_img[max(0,faceBox[1]-padding):\n",
    "                           min(faceBox[3]+padding,crop_img.shape[0]-1),max(0,faceBox[0]-padding)\n",
    "                           :min(faceBox[2]+padding, crop_img.shape[1]-1)]\n",
    "\n",
    "                blob=cv2.dnn.blobFromImage(face, 1.0, (227,227), MODEL_MEAN_VALUES, swapRB=False)\n",
    "                genderNet.setInput(blob)\n",
    "                genderPreds=genderNet.forward()\n",
    "                gender=genderList[genderPreds[0].argmax()]\n",
    "                print(f'Gender: {gender}')\n",
    "\n",
    "                ageNet.setInput(blob)\n",
    "                agePreds=ageNet.forward()\n",
    "                age=ageList[agePreds[0].argmax()]\n",
    "                print(f'Age: {age[1:-1]} years')\n",
    "\n",
    "                cv2.putText(resultImg, f'{gender}, {age}', (faceBox[0], faceBox[1]-10), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0,255,255), 2, cv2.LINE_AA)\n",
    "                #cv2.imshow(\"Detecting age and gender\", resultImg)\n",
    "                f=open('E:/billboard/output/'+str(i)+'_gender.txt','w')\n",
    "                f.write(str(gender))\n",
    "                f.close()\n",
    "                f=open('E:/billboard/output/'+str(i)+'_age.txt','w')\n",
    "                if age=='(0-2)' or age== '(4-6)':\n",
    "                    f.write('Child')\n",
    "                elif age=='(8-12)' :\n",
    "                    f.write('Teenager')\n",
    "                elif age== '(15-20)':\n",
    "                    f.write('Young Adult')\n",
    "                elif age== '(25-32)' or age== '(38-43)':\n",
    "                    f.write('Adult')\n",
    "                else:\n",
    "                    f.write('Senior')\n",
    "                    \n",
    "                        \n",
    "                f.close()\n",
    "                detect_and_save_faces(crop_img,i)\n",
    "    except:\n",
    "        print('Couldnt process person/'+str(i)+'.jpg')\n",
    "    \n",
    "    #detect_and_save_faces(crop_img,i)\n",
    "\n",
    "    cv2.putText(img, label, (x-10,y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "42453546",
   "metadata": {},
   "outputs": [],
   "source": [
    "#path+'final/e.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f8c26871",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread(path+'final/e.jpg')\n",
    "\n",
    "Width = image.shape[1]\n",
    "Height = image.shape[0]\n",
    "scale = 0.00392\n",
    "\n",
    "classes = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "354d18c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'E:/billboard/'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c6402e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path+'object_opencv/yolov3.txt', 'r') as f:\n",
    "    classes = [line.strip() for line in f.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1de379ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "COLORS = np.random.uniform(0, 255, size=(len(classes), 3))\n",
    "colors=COLORS\n",
    "net = cv2.dnn.readNet(path+'object_opencv/yolov3.weights', path+'object_opencv/yolov3.cfg')\n",
    "\n",
    "blob = cv2.dnn.blobFromImage(image, scale, (416,416), (0,0,0), True, crop=False)\n",
    "\n",
    "net.setInput(blob)\n",
    "\n",
    "outs = net.forward(get_output_layers(net))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9e762f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_ids = []\n",
    "confidences = []\n",
    "boxes = []\n",
    "conf_threshold = 0.5\n",
    "nms_threshold = 0.4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "153dff74",
   "metadata": {},
   "outputs": [],
   "source": [
    "for out in outs:\n",
    "    for detection in out:\n",
    "        scores = detection[0:2]\n",
    "        class_id = np.argmax(scores)\n",
    "        confidence = scores[class_id]\n",
    "        if confidence > 0.5:\n",
    "            center_x = int(detection[0] * Width)\n",
    "            center_y = int(detection[1] * Height)\n",
    "            w = int(detection[2] * Width)\n",
    "            h = int(detection[3] * Height)\n",
    "            x = center_x - w / 2\n",
    "            y = center_y - h / 2\n",
    "            class_ids.append(class_id)\n",
    "            confidences.append(float(confidence))\n",
    "            boxes.append([x, y, w, h])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e85573",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "804b2897",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect(image_file):\n",
    "    global path\n",
    "    try:\n",
    "        image = cv2.imread(image_file)\n",
    "\n",
    "        Width = image.shape[1]\n",
    "        Height = image.shape[0]\n",
    "        scale = 0.00392\n",
    "        class_ids = []\n",
    "        confidences = []\n",
    "        boxes = []\n",
    "        conf_threshold = 0.5\n",
    "        nms_threshold = 0.4\n",
    "\n",
    "        COLORS = np.random.uniform(0, 255, size=(len(classes), 3))\n",
    "\n",
    "        net = cv2.dnn.readNet(path+'object_opencv/yolov3.weights', path+'object_opencv/yolov3.cfg')\n",
    "\n",
    "        blob = cv2.dnn.blobFromImage(image, scale, (416,416), (0,0,0), True, crop=False)\n",
    "\n",
    "        net.setInput(blob)\n",
    "\n",
    "        outs = net.forward(get_output_layers(net))\n",
    "        #print(outs)\n",
    "        for out in outs:\n",
    "\n",
    "            for detection in out:\n",
    "                scores = detection[5:]\n",
    "                class_id = np.argmax(scores)\n",
    "                #print('class_id',class_id)\n",
    "                confidence = scores[class_id]\n",
    "                if confidence > 0.5 and class_id==0:\n",
    "                    center_x = int(detection[0] * Width)\n",
    "                    center_y = int(detection[1] * Height)\n",
    "                    w = int(detection[2] * Width)\n",
    "                    h = int(detection[3] * Height)\n",
    "                    x = center_x - w / 2\n",
    "                    y = center_y - h / 2\n",
    "                    class_ids.append(class_id)\n",
    "                    confidences.append(float(confidence))\n",
    "                    boxes.append([x, y, w, h])\n",
    "        indices = cv2.dnn.NMSBoxes(boxes, confidences, conf_threshold, nms_threshold)\n",
    "        c=0\n",
    "        for i in indices:\n",
    "            try:\n",
    "                box = boxes[i]\n",
    "            except:\n",
    "                i = i[0]\n",
    "                box = boxes[i]\n",
    "\n",
    "            x = box[0]\n",
    "            y = box[1]\n",
    "            w = box[2]\n",
    "            h = box[3]\n",
    "            #print('.....',class_ids[i])\n",
    "            print(x,y,w,h)\n",
    "            draw_prediction(c,image, class_ids[i], confidences[i], round(x-20), round(y-15), round(x+w+10), round(y+h+15))\n",
    "            c=c+1\n",
    "        #cv2.imshow(\"cam1\", image)\n",
    "        #cv2.waitKey()\n",
    "\n",
    "        cv2.imwrite(\"object-detection1.jpg\", image)\n",
    "        cv2.imwrite(\"E:/BillBoard_Web/web/object-detection1.jpg\", image)\n",
    "        cv2.destroyAllWindows()\n",
    "        results=[]\n",
    "        for i in class_ids:\n",
    "            print(classes[i])\n",
    "            results.append(classes[i])\n",
    "        return results,len(results)\n",
    "    except:\n",
    "        pass\n",
    "            \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5c50d45d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#path+'final/e.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "634946bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#detect(path+'final/10.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a3b9e7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing  input.jpg\n",
      "processing  input.jpg\n",
      "252.5 -14.0 321 434\n",
      "-29 435 232 584\n",
      "processing  input.jpg\n",
      "308.0 39.5 332 391\n",
      "24 446 288 650\n",
      "No face detected\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "processing  input.jpg\n",
      "274.5 -1.0 357 464\n",
      "-16 478 254 642\n",
      "No face detected\n",
      "9.0 20.5 334 415\n",
      "6 450 -11 353\n",
      "processing  input.jpg\n",
      "140.0 100.0 268 370\n",
      "85 485 120 418\n",
      "No face detected\n",
      "313.0 139.5 298 333\n",
      "124 488 293 621\n",
      "Gender: Female\n",
      "Age: 25-32 years\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "processing  input.jpg\n",
      "307.0 92.5 334 373\n",
      "78 480 287 651\n",
      "Gender: Male\n",
      "Age: 25-32 years\n",
      "95.0 70.5 258 389\n",
      "56 474 75 363\n",
      "No face detected\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "processing  input.jpg\n",
      "84.0 29.0 298 424\n",
      "14 468 64 392\n",
      "No face detected\n",
      "277.0 80.5 366 387\n",
      "66 482 257 653\n",
      "Gender: Male\n",
      "Age: 25-32 years\n",
      "316.0 49.0 204 312\n",
      "34 376 296 530\n",
      "No face detected\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "processing  input.jpg\n",
      "264.5 31.0 237 410\n",
      "16 456 244 512\n",
      "No face detected\n",
      "33.5 32.0 299 426\n",
      "17 473 14 342\n",
      "Gender: Male\n",
      "Age: 25-32 years\n",
      "378.5 67.0 253 416\n",
      "52 498 358 642\n",
      "No face detected\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "processing  input.jpg\n",
      "321.5 288.5 307 189\n",
      "274 492 302 638\n",
      "No face detected\n",
      "person\n",
      "person\n",
      "person\n",
      "processing  input.jpg\n",
      "415.0 235.5 224 241\n",
      "220 492 395 649\n",
      "No face detected\n",
      "person\n",
      "processing  input.jpg\n",
      "processing  input.jpg\n",
      "285.5 99.0 247 366\n",
      "84 480 266 542\n",
      "Gender: Male\n",
      "Age: 25-32 years\n",
      "466.5 118.0 171 322\n",
      "103 455 446 648\n",
      "Gender: Male\n",
      "Age: 25-32 years\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "processing  input.jpg\n",
      "processing  input.jpg\n",
      "311.5 204.0 301 274\n",
      "189 493 292 622\n",
      "No face detected\n",
      "65.0 -5.5 592 495\n",
      "-20 504 45 667\n",
      "No face detected\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "processing  input.jpg\n",
      "306.5 204.0 319 276\n",
      "189 495 286 636\n",
      "Gender: Female\n",
      "Age: 4-6 years\n",
      "person\n",
      "person\n",
      "processing  input.jpg\n",
      "processing  input.jpg\n",
      "22.0 -0.5 600 327\n",
      "-16 342 2 632\n",
      "processing  input.jpg\n",
      "26.5 22.5 583 437\n",
      "8 474 6 620\n",
      "No face detected\n",
      "person\n",
      "processing  input.jpg\n",
      "106.0 7.5 518 461\n",
      "-8 484 86 634\n",
      "No face detected\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "processing  input.jpg\n",
      "106.0 7.5 518 461\n",
      "-8 484 86 634\n",
      "No face detected\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "processing  input.jpg\n",
      "106.0 7.5 518 461\n",
      "-8 484 86 634\n",
      "No face detected\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "processing  input.jpg\n",
      "106.0 7.5 518 461\n",
      "-8 484 86 634\n",
      "No face detected\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "processing  input.jpg\n",
      "106.0 7.5 518 461\n",
      "-8 484 86 634\n",
      "No face detected\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "processing  input.jpg\n",
      "106.0 7.5 518 461\n",
      "-8 484 86 634\n",
      "No face detected\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "processing  input.jpg\n",
      "106.0 7.5 518 461\n",
      "-8 484 86 634\n",
      "No face detected\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "processing  input.jpg\n",
      "106.0 7.5 518 461\n",
      "-8 484 86 634\n",
      "No face detected\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "processing  input.jpg\n",
      "106.0 7.5 518 461\n",
      "-8 484 86 634\n",
      "No face detected\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "processing  input.jpg\n",
      "106.0 7.5 518 461\n",
      "-8 484 86 634\n",
      "No face detected\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "processing  input.jpg\n",
      "106.0 7.5 518 461\n",
      "-8 484 86 634\n",
      "No face detected\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "processing  input.jpg\n",
      "106.0 7.5 518 461\n",
      "-8 484 86 634\n",
      "No face detected\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "processing  input.jpg\n",
      "106.0 7.5 518 461\n",
      "-8 484 86 634\n",
      "No face detected\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "processing  input.jpg\n",
      "106.0 7.5 518 461\n",
      "-8 484 86 634\n",
      "No face detected\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "processing  input.jpg\n",
      "106.0 7.5 518 461\n",
      "-8 484 86 634\n",
      "No face detected\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "processing  input.jpg\n",
      "106.0 7.5 518 461\n",
      "-8 484 86 634\n",
      "No face detected\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "processing  input.jpg\n",
      "106.0 7.5 518 461\n",
      "-8 484 86 634\n",
      "No face detected\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "processing  input.jpg\n",
      "106.0 7.5 518 461\n",
      "-8 484 86 634\n",
      "No face detected\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "processing  input.jpg\n",
      "106.0 7.5 518 461\n",
      "-8 484 86 634\n",
      "No face detected\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "processing  input.jpg\n",
      "106.0 7.5 518 461\n",
      "-8 484 86 634\n",
      "No face detected\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "processing  input.jpg\n",
      "359.5 13.5 277 453\n",
      "-2 482 340 646\n",
      "No face detected\n",
      "-10.5 2.0 351 268\n",
      "-13 285 -30 350\n",
      "processing  input.jpg\n",
      "395.5 -5.0 237 350\n",
      "-20 360 376 642\n",
      "processing  input.jpg\n",
      "298.0 1.5 348 473\n",
      "-14 490 278 656\n",
      "No face detected\n",
      "-1.0 -8.5 260 481\n",
      "-24 488 -21 269\n",
      "processing  input.jpg\n",
      "-2.0 0.5 174 31\n",
      "-14 46 -22 182\n",
      "processing  input.jpg\n",
      "328.5 30.0 183 434\n",
      "15 479 308 522\n",
      "Gender: Male\n",
      "Age: 8-12 years\n",
      "61.5 50.5 249 433\n",
      "36 498 42 320\n",
      "No face detected\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "f 0.jpg\n",
      "['0', '1', '2', '3', '4', '5', '6', '7']\n",
      "E:/billboard/Dataset/0/0.jpg\n",
      "E:/billboard/Dataset/1/0.jpg\n",
      "E:/billboard/Dataset/2/0.jpg\n",
      "E:/billboard/Dataset/3/0.jpg\n",
      "E:/billboard/Dataset/4/0.jpg\n",
      "E:/billboard/Dataset/5/0.jpg\n",
      "E:/billboard/Dataset/6/0.jpg\n",
      "E:/billboard/Dataset/7/0.jpg\n",
      "done extraction\n",
      "done training\n",
      "inside for\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vinag\\.conda\\envs\\myenv\\lib\\site-packages\\ipykernel_launcher.py:42: DeprecationWarning: textsize is deprecated and will be removed in Pillow 10 (2023-07-01). Use textbbox or textlength instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Person is: 4\n",
      "Current date is: 2024-04-23\n",
      "Current Day: Tuesday\n",
      "Current Time: 17:17:16\n",
      "Week of the Month: 4\n",
      "17 <class 'int'>\n",
      "4 Teenager Male 2024-04-23 17-18 TUESDAY Week 4\n",
      "processing  input.jpg\n",
      "316.5 -3.5 273 351\n",
      "-18 362 296 600\n",
      "processing  input.jpg\n",
      "357.5 8.0 281 452\n",
      "-7 475 338 648\n",
      "No face detected\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "processing  input.jpg\n",
      "processing  input.jpg\n",
      "processing  input.jpg\n",
      "292.5 3.0 355 474\n",
      "-12 492 272 658\n",
      "No face detected\n",
      "person\n",
      "person\n",
      "processing  input.jpg\n",
      "294.5 -3.5 339 487\n",
      "-18 498 274 644\n",
      "No face detected\n",
      "-0.5 169.0 239 302\n",
      "154 486 -20 248\n",
      "processing  input.jpg\n",
      "-4.5 142.0 147 340\n",
      "127 497 -24 152\n",
      "processing  input.jpg\n",
      "275.0 16.0 358 454\n",
      "1 485 255 643\n",
      "Gender: Male\n",
      "Age: 25-32 years\n",
      "131.5 377.5 169 101\n",
      "362 494 112 310\n",
      "No face detected\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "f 0.jpg\n",
      "['0', '1', '2', '3', '4', '5', '6', '7']\n",
      "E:/billboard/Dataset/0/0.jpg\n",
      "E:/billboard/Dataset/1/0.jpg\n",
      "E:/billboard/Dataset/2/0.jpg\n",
      "E:/billboard/Dataset/3/0.jpg\n",
      "E:/billboard/Dataset/4/0.jpg\n",
      "E:/billboard/Dataset/5/0.jpg\n",
      "E:/billboard/Dataset/6/0.jpg\n",
      "E:/billboard/Dataset/7/0.jpg\n",
      "done extraction\n",
      "done training\n",
      "inside for\n",
      "The Person is: 1\n",
      "Current date is: 2024-04-23\n",
      "Current Day: Tuesday\n",
      "Current Time: 17:18:04\n",
      "Week of the Month: 4\n",
      "17 <class 'int'>\n",
      "1 Adult Male 2024-04-23 17-18 TUESDAY Week 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vinag\\.conda\\envs\\myenv\\lib\\site-packages\\ipykernel_launcher.py:42: DeprecationWarning: textsize is deprecated and will be removed in Pillow 10 (2023-07-01). Use textbbox or textlength instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing  input.jpg\n",
      "360.0 146.5 212 327\n",
      "132 488 340 582\n",
      "Gender: Male\n",
      "Age: 8-12 years\n",
      "Gender: Female\n",
      "Age: 8-12 years\n",
      "133.0 154.0 254 314\n",
      "139 483 113 397\n",
      "Gender: Female\n",
      "Age: 25-32 years\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "f 0.jpg\n",
      "['0', '1', '2', '3', '4', '5', '6', '7']\n",
      "E:/billboard/Dataset/0/0.jpg\n",
      "E:/billboard/Dataset/1/0.jpg\n",
      "E:/billboard/Dataset/2/0.jpg\n",
      "E:/billboard/Dataset/3/0.jpg\n",
      "E:/billboard/Dataset/4/0.jpg\n",
      "E:/billboard/Dataset/5/0.jpg\n",
      "E:/billboard/Dataset/6/0.jpg\n",
      "E:/billboard/Dataset/7/0.jpg\n",
      "done extraction\n",
      "done training\n",
      "inside for\n",
      "The Person is: 3\n",
      "Current date is: 2024-04-23\n",
      "Current Day: Tuesday\n",
      "Current Time: 17:18:20\n",
      "Week of the Month: 4\n",
      "17 <class 'int'>\n",
      "3 Teenager Female 2024-04-23 17-18 TUESDAY Week 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vinag\\.conda\\envs\\myenv\\lib\\site-packages\\ipykernel_launcher.py:42: DeprecationWarning: textsize is deprecated and will be removed in Pillow 10 (2023-07-01). Use textbbox or textlength instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing  input.jpg\n",
      "385.5 71.5 257 409\n",
      "56 496 366 652\n",
      "No face detected\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "processing  input.jpg\n",
      "318.0 35.0 328 424\n",
      "20 474 298 656\n",
      "No face detected\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "processing  input.jpg\n",
      "384.5 236.0 251 238\n",
      "221 489 364 646\n",
      "No face detected\n",
      "person\n",
      "processing  input.jpg\n",
      "254.5 -2.0 341 484\n",
      "-17 497 234 606\n",
      "No face detected\n",
      "person\n",
      "person\n",
      "person\n",
      "processing  input.jpg\n",
      "processing  input.jpg\n",
      "processing  input.jpg\n",
      "processing  input.jpg\n",
      "processing  input.jpg\n",
      "processing  input.jpg\n",
      "processing  input.jpg\n",
      "processing  input.jpg\n",
      "processing  input.jpg\n",
      "processing  input.jpg\n",
      "processing  input.jpg\n",
      "processing  input.jpg\n",
      "processing  input.jpg\n",
      "processing  input.jpg\n",
      "processing  input.jpg\n",
      "processing  input.jpg\n",
      "processing  input.jpg\n",
      "processing  input.jpg\n",
      "processing  input.jpg\n",
      "processing  input.jpg\n",
      "processing  input.jpg\n",
      "processing  input.jpg\n",
      "processing  input.jpg\n",
      "383.0 58.5 248 419\n",
      "44 492 363 641\n",
      "No face detected\n",
      "58.0 58.5 250 377\n",
      "44 450 38 318\n",
      "No face detected\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "processing  input.jpg\n",
      "75.5 23.5 303 429\n",
      "8 468 56 388\n",
      "No face detected\n",
      "324.0 48.0 316 430\n",
      "33 493 304 650\n",
      "No face detected\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "processing  input.jpg\n",
      "processing  input.jpg\n",
      "71.5 34.0 487 422\n",
      "19 471 52 568\n",
      "No face detected\n",
      "463.5 176.5 183 185\n",
      "162 376 444 656\n",
      "No face detected\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "processing  input.jpg\n",
      "431.5 250.5 209 151\n",
      "236 416 412 650\n",
      "Gender: Female\n",
      "Age: 15-20 years\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "f 0.jpg\n",
      "['0', '1', '2', '3', '4', '5', '6', '7']\n",
      "E:/billboard/Dataset/0/0.jpg\n",
      "E:/billboard/Dataset/1/0.jpg\n",
      "E:/billboard/Dataset/2/0.jpg\n",
      "E:/billboard/Dataset/3/0.jpg\n",
      "E:/billboard/Dataset/4/0.jpg\n",
      "E:/billboard/Dataset/5/0.jpg\n",
      "E:/billboard/Dataset/6/0.jpg\n",
      "E:/billboard/Dataset/7/0.jpg\n",
      "done extraction\n",
      "done training\n",
      "processing  input.jpg\n",
      "511.0 -1.0 130 314\n",
      "-16 328 491 651\n",
      "processing  input.jpg\n",
      "-5.0 27.0 270 426\n",
      "12 468 -25 275\n",
      "processing  input.jpg\n",
      "-1.5 264.5 183 219\n",
      "250 498 -22 192\n",
      "processing  input.jpg\n",
      "-3.0 271.0 176 206\n",
      "256 492 -23 183\n",
      "processing  input.jpg\n",
      "217.0 171.0 404 304\n",
      "156 490 197 631\n",
      "No face detected\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "processing  input.jpg\n",
      "198.5 0.5 143 125\n",
      "-14 140 178 352\n",
      "processing  input.jpg\n",
      "330.0 112.5 134 165\n",
      "98 292 310 474\n",
      "No face detected\n",
      "521.5 123.5 99 83\n",
      "108 222 502 630\n",
      "Gender: Female\n",
      "Age: 25-32 years\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "processing  input.jpg\n",
      "227.5 99.5 155 159\n",
      "84 274 208 392\n",
      "Gender: Female\n",
      "Age: 60-100 years\n",
      "380.0 117.0 84 76\n",
      "102 208 360 474\n",
      "No face detected\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "processing  input.jpg\n",
      "380.0 118.5 82 73\n",
      "104 206 360 472\n",
      "Gender: Male\n",
      "Age: 25-32 years\n",
      "230.0 90.0 148 110\n",
      "75 215 210 388\n",
      "No face detected\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "processing  input.jpg\n",
      "210.5 179.0 159 174\n",
      "164 368 190 380\n",
      "Gender: Male\n",
      "Age: 8-12 years\n",
      "385.5 -2.0 247 316\n",
      "-17 329 366 642\n",
      "processing  input.jpg\n",
      "387.0 3.5 246 327\n",
      "-12 346 367 643\n",
      "processing  input.jpg\n",
      "-1.5 7.0 307 312\n",
      "-8 334 -22 316\n",
      "processing  input.jpg\n",
      "108.0 -2.5 420 357\n",
      "-18 370 88 538\n",
      "processing  input.jpg\n",
      "288.0 23.5 364 353\n",
      "8 392 268 662\n",
      "Gender: Male\n",
      "Age: 25-32 years\n",
      "102.0 15.5 210 285\n",
      "0 316 82 322\n",
      "Gender: Female\n",
      "Age: 25-32 years\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "f 1.jpg\n",
      "['0', '1', '2', '3', '4', '5', '6', '7']\n",
      "E:/billboard/Dataset/0/0.jpg\n",
      "E:/billboard/Dataset/1/0.jpg\n",
      "E:/billboard/Dataset/2/0.jpg\n",
      "E:/billboard/Dataset/3/0.jpg\n",
      "E:/billboard/Dataset/4/0.jpg\n",
      "E:/billboard/Dataset/5/0.jpg\n",
      "E:/billboard/Dataset/6/0.jpg\n",
      "E:/billboard/Dataset/7/0.jpg\n",
      "done extraction\n",
      "done training\n",
      "processing  input.jpg\n",
      "221.5 72.0 407 350\n",
      "57 437 202 638\n",
      "Gender: Female\n",
      "Age: 15-20 years\n",
      "-0.5 88.0 207 302\n",
      "73 405 -20 216\n",
      "processing  input.jpg\n",
      "302.0 40.5 346 341\n",
      "26 396 282 658\n",
      "Gender: Male\n",
      "Age: 15-20 years\n",
      "7.5 62.5 273 295\n",
      "48 372 -12 290\n",
      "processing  input.jpg\n",
      "-4.0 43.0 250 410\n",
      "28 468 -24 256\n",
      "processing  input.jpg\n",
      "170.5 50.0 485 400\n",
      "35 465 150 666\n",
      "Gender: Female\n",
      "Age: 25-32 years\n",
      "-3.0 71.0 170 414\n",
      "56 500 -23 177\n",
      "processing  input.jpg\n",
      "99.0 11.0 542 466\n",
      "-4 492 79 651\n",
      "No face detected\n",
      "0.0 55.0 150 426\n",
      "40 496 -20 160\n",
      "processing  input.jpg\n",
      "109.0 16.5 532 455\n",
      "2 486 89 651\n",
      "Gender: Male\n",
      "Age: 25-32 years\n",
      "1.5 59.5 157 425\n",
      "44 500 -18 168\n",
      "processing  input.jpg\n",
      "114.0 70.0 528 400\n",
      "55 485 94 652\n",
      "Gender: Male\n",
      "Age: 25-32 years\n",
      "-2.5 211.0 125 266\n",
      "196 492 -22 132\n",
      "processing  input.jpg\n",
      "93.5 57.0 551 416\n",
      "42 488 74 654\n",
      "Gender: Male\n",
      "Age: 25-32 years\n",
      "-2.5 176.5 131 293\n",
      "162 484 -22 138\n",
      "processing  input.jpg\n",
      "21.0 33.5 612 405\n",
      "18 454 1 643\n",
      "No face detected\n",
      "-0.5 22.5 121 295\n",
      "8 332 -20 130\n",
      "processing  input.jpg\n",
      "85.5 31.5 567 417\n",
      "16 464 66 662\n",
      "Gender: Female\n",
      "Age: 38-43 years\n",
      "-3.0 33.0 226 410\n",
      "18 458 -23 233\n",
      "processing  input.jpg\n",
      "98.0 44.0 552 414\n",
      "29 473 78 660\n",
      "Gender: Male\n",
      "Age: 15-20 years\n",
      "0.5 93.5 171 381\n",
      "78 490 -20 182\n",
      "processing  input.jpg\n",
      "103.0 34.5 544 429\n",
      "20 478 83 657\n",
      "Gender: Male\n",
      "Age: 25-32 years\n",
      "-5.5 98.0 199 372\n",
      "83 485 -26 204\n",
      "processing  input.jpg\n",
      "23.5 53.5 613 425\n",
      "38 494 4 646\n",
      "Gender: Female\n",
      "Age: 25-32 years\n",
      "4.0 95.5 148 381\n",
      "80 492 -16 162\n",
      "processing  input.jpg\n",
      "332.0 149.5 268 335\n",
      "134 500 312 610\n",
      "Gender: Female\n",
      "Age: 25-32 years\n",
      "7.5 105.0 289 288\n",
      "90 408 -12 306\n",
      "processing  input.jpg\n",
      "304.5 153.0 257 328\n",
      "138 496 284 572\n",
      "Gender: Female\n",
      "Age: 25-32 years\n",
      "5.5 96.0 255 302\n",
      "81 413 -14 270\n",
      "processing  input.jpg\n",
      "282.5 138.5 261 345\n",
      "124 498 262 554\n",
      "Gender: Female\n",
      "Age: 25-32 years\n",
      "1.5 82.5 251 317\n",
      "68 414 -18 262\n",
      "processing  input.jpg\n",
      "255.0 172.0 256 308\n",
      "157 495 235 521\n",
      "Gender: Female\n",
      "Age: 25-32 years\n",
      "-5.0 96.0 230 342\n",
      "81 453 -25 235\n",
      "processing  input.jpg\n",
      "260.5 95.0 253 310\n",
      "80 420 240 524\n",
      "Gender: Female\n",
      "Age: 25-32 years\n",
      "519.0 141.0 120 342\n",
      "126 498 499 649\n",
      "No face detected\n",
      "-4.0 12.5 248 315\n",
      "-2 342 -24 254\n",
      "processing  input.jpg\n",
      "263.5 105.0 241 340\n",
      "90 460 244 514\n",
      "Gender: Male\n",
      "Age: 25-32 years\n",
      "-2.0 28.5 236 331\n",
      "14 374 -22 244\n",
      "processing  input.jpg\n",
      "239.0 87.0 230 326\n",
      "72 428 219 479\n",
      "Gender: Female\n",
      "Age: 25-32 years\n",
      "467.0 29.5 170 481\n",
      "14 526 447 647\n",
      "No face detected\n",
      "-3.5 7.5 213 327\n",
      "-8 350 -24 220\n",
      "processing  input.jpg\n",
      "234.5 131.0 231 306\n",
      "116 452 214 476\n",
      "Gender: Female\n",
      "Age: 25-32 years\n",
      "461.5 40.0 175 464\n",
      "25 519 442 646\n",
      "No face detected\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "processing  input.jpg\n",
      "232.5 119.5 235 321\n",
      "104 456 212 478\n",
      "Gender: Female\n",
      "Age: 25-32 years\n",
      "463.5 33.5 173 465\n",
      "18 514 444 646\n",
      "No face detected\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "processing  input.jpg\n",
      "219.0 77.0 240 338\n",
      "62 430 199 469\n",
      "Gender: Female\n",
      "Age: 25-32 years\n",
      "471.0 23.0 168 448\n",
      "8 486 451 649\n",
      "No face detected\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "processing  input.jpg\n",
      "232.5 72.5 229 333\n",
      "58 420 212 472\n",
      "Gender: Male\n",
      "Age: 25-32 years\n",
      "466.0 19.0 172 454\n",
      "4 488 446 648\n",
      "No face detected\n",
      "0.0 7.0 172 306\n",
      "-8 328 -20 182\n",
      "f 0.jpg\n",
      "['0', '1', '2', '3', '4', '5', '6', '7']\n",
      "E:/billboard/Dataset/0/0.jpg\n",
      "E:/billboard/Dataset/1/0.jpg\n",
      "E:/billboard/Dataset/2/0.jpg\n",
      "E:/billboard/Dataset/3/0.jpg\n",
      "E:/billboard/Dataset/4/0.jpg\n",
      "E:/billboard/Dataset/5/0.jpg\n",
      "E:/billboard/Dataset/6/0.jpg\n",
      "E:/billboard/Dataset/7/0.jpg\n",
      "done extraction\n",
      "done training\n",
      "inside for\n",
      "The Person is: 4\n",
      "Current date is: 2024-04-23\n",
      "Current Day: Tuesday\n",
      "Current Time: 17:24:16\n",
      "Week of the Month: 4\n",
      "17 <class 'int'>\n",
      "4 Adult Male 2024-04-23 17-18 TUESDAY Week 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vinag\\.conda\\envs\\myenv\\lib\\site-packages\\ipykernel_launcher.py:42: DeprecationWarning: textsize is deprecated and will be removed in Pillow 10 (2023-07-01). Use textbbox or textlength instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing  input.jpg\n",
      "332.5 -6.0 253 352\n",
      "-21 361 312 596\n",
      "processing  input.jpg\n",
      "280.0 130.5 252 317\n",
      "116 462 260 542\n",
      "Gender: Male\n",
      "Age: 25-32 years\n",
      "-9.5 59.0 247 342\n",
      "44 416 -30 248\n",
      "processing  input.jpg\n",
      "378.5 1.0 259 472\n",
      "-14 488 358 648\n",
      "No face detected\n",
      "142.5 -1.0 251 356\n",
      "-16 370 122 404\n",
      "processing  input.jpg\n",
      "135.5 -2.5 253 357\n",
      "-18 370 116 398\n",
      "processing  input.jpg\n",
      "318.0 16.0 320 432\n",
      "1 463 298 648\n",
      "No face detected\n",
      "140.0 -3.0 246 358\n",
      "-18 370 120 396\n",
      "processing  input.jpg\n",
      "321.0 18.5 310 427\n",
      "4 460 301 641\n",
      "No face detected\n",
      "128.5 1.0 201 350\n",
      "-14 366 108 340\n",
      "processing  input.jpg\n",
      "310.5 24.0 323 422\n",
      "9 461 290 644\n",
      "No face detected\n",
      "135.5 -10.5 245 407\n",
      "-26 412 116 390\n",
      "processing  input.jpg\n",
      "277.0 23.0 366 422\n",
      "8 460 257 653\n",
      "Gender: Male\n",
      "Age: 25-32 years\n",
      "116.5 14.5 249 357\n",
      "0 386 96 376\n",
      "Gender: Male\n",
      "Age: 25-32 years\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "processing  input.jpg\n",
      "169.5 47.0 239 288\n",
      "32 350 150 418\n",
      "Gender: Male\n",
      "Age: 8-12 years\n",
      "388.5 31.0 249 416\n",
      "16 462 368 648\n",
      "Gender: Female\n",
      "Age: 25-32 years\n",
      "-1.5 42.5 67 227\n",
      "28 284 -22 76\n",
      "f 0.jpg\n",
      "['0', '1', '2', '3', '4', '5', '6', '7']\n",
      "E:/billboard/Dataset/0/0.jpg\n",
      "E:/billboard/Dataset/1/0.jpg\n",
      "E:/billboard/Dataset/2/0.jpg\n",
      "E:/billboard/Dataset/3/0.jpg\n",
      "E:/billboard/Dataset/4/0.jpg\n",
      "E:/billboard/Dataset/5/0.jpg\n",
      "E:/billboard/Dataset/6/0.jpg\n",
      "E:/billboard/Dataset/7/0.jpg\n",
      "done extraction\n",
      "done training\n",
      "inside for\n",
      "The Person is: 4\n",
      "Current date is: 2024-04-23\n",
      "Current Day: Tuesday\n",
      "Current Time: 17:25:07\n",
      "Week of the Month: 4\n",
      "17 <class 'int'>\n",
      "4 Teenager Male 2024-04-23 17-18 TUESDAY Week 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vinag\\.conda\\envs\\myenv\\lib\\site-packages\\ipykernel_launcher.py:42: DeprecationWarning: textsize is deprecated and will be removed in Pillow 10 (2023-07-01). Use textbbox or textlength instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing  input.jpg\n",
      "273.0 -2.5 194 271\n",
      "-18 284 253 477\n",
      "processing  input.jpg\n",
      "267.0 0.0 202 264\n",
      "-15 279 247 479\n",
      "processing  input.jpg\n",
      "267.0 0.0 202 264\n",
      "-15 279 247 479\n",
      "processing  input.jpg\n",
      "267.0 0.0 202 264\n",
      "-15 279 247 479\n",
      "processing  input.jpg\n",
      "267.0 0.0 202 264\n",
      "-15 279 247 479\n",
      "processing  input.jpg\n",
      "267.0 0.0 202 264\n",
      "-15 279 247 479\n",
      "processing  input.jpg\n",
      "267.0 0.0 202 264\n",
      "-15 279 247 479\n",
      "processing  input.jpg\n",
      "267.0 0.0 202 264\n",
      "-15 279 247 479\n",
      "processing  input.jpg\n",
      "267.0 0.0 202 264\n",
      "-15 279 247 479\n",
      "processing  input.jpg\n",
      "267.0 0.0 202 264\n",
      "-15 279 247 479\n",
      "processing  input.jpg\n",
      "267.0 0.0 202 264\n",
      "-15 279 247 479\n",
      "processing  input.jpg\n",
      "267.0 0.0 202 264\n",
      "-15 279 247 479\n",
      "processing  input.jpg\n",
      "267.0 0.0 202 264\n",
      "-15 279 247 479\n",
      "processing  input.jpg\n",
      "267.0 0.0 202 264\n",
      "-15 279 247 479\n",
      "processing  input.jpg\n",
      "267.0 0.0 202 264\n",
      "-15 279 247 479\n",
      "processing  input.jpg\n",
      "267.0 0.0 202 264\n",
      "-15 279 247 479\n",
      "processing  input.jpg\n",
      "267.0 0.0 202 264\n",
      "-15 279 247 479\n",
      "processing  input.jpg\n",
      "267.0 0.0 202 264\n",
      "-15 279 247 479\n",
      "processing  input.jpg\n",
      "267.0 0.0 202 264\n",
      "-15 279 247 479\n",
      "processing  input.jpg\n",
      "267.0 0.0 202 264\n",
      "-15 279 247 479\n",
      "processing  input.jpg\n",
      "267.0 0.0 202 264\n",
      "-15 279 247 479\n",
      "processing  input.jpg\n",
      "267.0 0.0 202 264\n",
      "-15 279 247 479\n",
      "processing  input.jpg\n",
      "267.0 0.0 202 264\n",
      "-15 279 247 479\n",
      "processing  input.jpg\n",
      "267.0 0.0 202 264\n",
      "-15 279 247 479\n",
      "processing  input.jpg\n",
      "267.0 0.0 202 264\n",
      "-15 279 247 479\n",
      "processing  input.jpg\n",
      "267.0 0.0 202 264\n",
      "-15 279 247 479\n",
      "processing  input.jpg\n",
      "267.0 0.0 202 264\n",
      "-15 279 247 479\n",
      "processing  input.jpg\n",
      "267.0 0.0 202 264\n",
      "-15 279 247 479\n",
      "processing  input.jpg\n",
      "267.0 0.0 202 264\n",
      "-15 279 247 479\n",
      "processing  input.jpg\n",
      "267.0 0.0 202 264\n",
      "-15 279 247 479\n",
      "processing  input.jpg\n",
      "267.0 0.0 202 264\n",
      "-15 279 247 479\n",
      "processing  input.jpg\n",
      "267.0 0.0 202 264\n",
      "-15 279 247 479\n",
      "processing  input.jpg\n",
      "267.0 0.0 202 264\n",
      "-15 279 247 479\n",
      "processing  input.jpg\n",
      "267.0 0.0 202 264\n",
      "-15 279 247 479\n",
      "processing  input.jpg\n",
      "267.0 0.0 202 264\n",
      "-15 279 247 479\n",
      "processing  input.jpg\n",
      "267.0 0.0 202 264\n",
      "-15 279 247 479\n",
      "processing  input.jpg\n",
      "processing  input.jpg\n",
      "processing  input.jpg\n",
      "processing  input.jpg\n",
      "processing  input.jpg\n",
      "processing  input.jpg\n",
      "processing  input.jpg\n",
      "processing  input.jpg\n",
      "processing  input.jpg\n",
      "processing  input.jpg\n",
      "processing  input.jpg\n",
      "processing  input.jpg\n",
      "processing  input.jpg\n",
      "processing  input.jpg\n",
      "processing  input.jpg\n",
      "processing  input.jpg\n",
      "processing  input.jpg\n",
      "processing  input.jpg\n",
      "processing  input.jpg\n",
      "processing  input.jpg\n",
      "processing  input.jpg\n",
      "processing  input.jpg\n",
      "processing  input.jpg\n",
      "processing  input.jpg\n",
      "processing  input.jpg\n",
      "processing  input.jpg\n",
      "processing  input.jpg\n",
      "processing  input.jpg\n",
      "processing  input.jpg\n",
      "processing  input.jpg\n",
      "processing  input.jpg\n",
      "processing  input.jpg\n",
      "processing  input.jpg\n",
      "processing  input.jpg\n",
      "processing  input.jpg\n",
      "processing  input.jpg\n",
      "processing  input.jpg\n",
      "processing  input.jpg\n",
      "processing  input.jpg\n",
      "processing  input.jpg\n",
      "processing  input.jpg\n",
      "processing  input.jpg\n",
      "processing  input.jpg\n",
      "processing  input.jpg\n",
      "processing  input.jpg\n",
      "processing  input.jpg\n",
      "processing  input.jpg\n",
      "processing  input.jpg\n",
      "processing  input.jpg\n",
      "processing  input.jpg\n",
      "processing  input.jpg\n",
      "processing  input.jpg\n",
      "processing  input.jpg\n",
      "processing  input.jpg\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(1)\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    cv2.imwrite('input.jpg', frame)\n",
    "    cv2.imwrite('E:/BillBoard_Web/web/live.png',frame)\n",
    "    file_path='input.jpg'\n",
    "    print('processing ',file_path)\n",
    "    \n",
    "    if not ret:\n",
    "        break\n",
    "    #cv2.imshow(\"Live Camera\", frame)\n",
    "    for file in os.listdir('E:/billboard/final/detected_faces/'):\n",
    "        if os.path.isfile(os.path.join('E:/billboard/final/detected_faces/', file)):\n",
    "            os.remove('E:/billboard/final/detected_faces/'+file)\n",
    "    detect('E:/billboard/final/input.jpg')\n",
    "    time.sleep(2)\n",
    "    files = []\n",
    "    for file in os.listdir('E:/billboard/final/detected_faces/'):\n",
    "        if os.path.isfile(os.path.join('E:/billboard/final/detected_faces/', file)):\n",
    "            files.append(file)\n",
    "    c=0\n",
    "    for f in files:\n",
    "        print('f',f)\n",
    "        face_recognition('E:/billboard/final/detected_faces/'+f,c)\n",
    "        c=c+1\n",
    "        time.sleep(2)\n",
    "    \n",
    "    if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e67708",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def download():\n",
    "    url = 'http://192.168.0.140:4747/video'\n",
    "    file_name = '1.png'\n",
    "\n",
    "    res = requests.get(url, stream = True)\n",
    "\n",
    "    if res.status_code == 200:\n",
    "        with open(file_name,'wb') as f:\n",
    "            shutil.copyfileobj(res.raw, f)\n",
    "        print('Image sucessfully Downloaded: ',file_name)\n",
    "    else:\n",
    "        print('Image Couldn\\'t be retrieved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2561f0be",
   "metadata": {},
   "outputs": [],
   "source": [
    "download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c4cccb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "detect(path+'final/1.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "370c5e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "while True:\n",
    "    download()\n",
    "    detect(path+'final/1.png')\n",
    "    \n",
    "    \n",
    "    time.sleep(10)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e0f540",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load camera\n",
    "cap = cv2.VideoCapture('http://192.168.139.234:81/stream')\n",
    "\n",
    "while True:\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    height, width, channels = frame.shape\n",
    "\n",
    "    # Detecting objects\n",
    "    blob = cv2.dnn.blobFromImage(frame, 0.00392, (416, 416), (0, 0, 0), True, crop=False)\n",
    "    net.setInput(blob)\n",
    "    \n",
    "\n",
    "    outs = net.forward(get_output_layers(net))\n",
    "    count=0\n",
    "    # Showing informations on the screen\n",
    "    for out in outs:\n",
    "        for detection in out:\n",
    "            scores = detection[5:]\n",
    "            class_id = np.argmax(scores)\n",
    "            confidence = scores[class_id]\n",
    "            if confidence > 0.5 :\n",
    "                # Object detected\n",
    "                count=count+1\n",
    "                center_x = int(detection[0] * width)\n",
    "                center_y = int(detection[1] * height)\n",
    "                w = int(detection[2] * width)\n",
    "                h = int(detection[3] * height)\n",
    "\n",
    "                # Rectangle coordinates\n",
    "                x = int(center_x - w / 2)\n",
    "                y = int(center_y - h / 2)\n",
    "\n",
    "                # Draw rectangle and label\n",
    "                cv2.rectangle(frame, (x, y), (x + w, y + h), colors[0], 2)\n",
    "                cv2.putText(frame, classes[class_id], (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, colors[0], 2)\n",
    "                if classes[class_id]!='':\n",
    "                    print(classes[class_id])\n",
    "                    f=open('output.txt','w')\n",
    "                    f.write(str(classes[class_id]))\n",
    "                    f.close()\n",
    "                \n",
    "\n",
    "    # Display the resulting frame\n",
    "    #cv2.imshow('Camera '+str(count), frame)\n",
    "    #print('Total count ',count)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# When everything done, release the capture\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad60084",
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in os.walk('E:/2024/billboard/final/detected_faces/'):\n",
    "    print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ecd3b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = []\n",
    "for file in os.listdir('E:/2024/billboard/final/detected_faces/'):\n",
    "    if os.path.isfile(os.path.join('E:/2024/billboard/final/detected_faces/', file)):\n",
    "        files.append(file)\n",
    "for f in files:\n",
    "    print('f',f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26736220",
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in os.listdir('E:/2024/billboard/final/detected_faces/'):\n",
    "    if os.path.isfile(os.path.join('E:/2024/billboard/final/detected_faces/', file)):\n",
    "        os.remove('E:/2024/billboard/final/detected_faces/'+file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db2aaff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
